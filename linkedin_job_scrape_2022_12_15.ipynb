{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SKwP6xqo6b8d"
   },
   "outputs": [],
   "source": [
    "# https://blog.devgenius.io/how-to-build-a-scraping-tool-for-linkedin-in-7-minutes-tool-data-science-csv-selenium-beautifulsoup-python-a673f12ac579\n",
    "# !pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QqvrsGn36KDD"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the job name: Data Scientist\n"
     ]
    }
   ],
   "source": [
    "job_name = input(\"Enter the job name: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the job location: United States\n"
     ]
    }
   ],
   "source": [
    "country_name =input(\"Enter the job location: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "FqYsJGMi6ops",
    "outputId": "ab5777d2-c7fd-457f-a629-592c36ae2390"
   },
   "outputs": [],
   "source": [
    "# job_name = \"Data Scientist\"\n",
    "# country_name = \"United States\"\n",
    "\n",
    "job_url =\"\";\n",
    "for item in job_name.split(\" \"):\n",
    "    if item != job_name.split(\" \")[-1]:\n",
    "        job_url = job_url + item + \"%20\"\n",
    "    else:\n",
    "        job_url = job_url + item\n",
    "\n",
    "country_url =\"\";\n",
    "for item in country_name.split(\" \"):\n",
    "    if item != country_name.split(\" \")[-1]:\n",
    "        country_url = country_url + item + \"%20\"\n",
    "    else:\n",
    "        country_url = country_url + item\n",
    "\n",
    "url = \"https://www.linkedin.com/jobs/search?keywords={0}&location={1}&geoId=103644278&trk=public_jobs_jobs-search-bar_search-submit&position=1&pageNum=0\".format(job_url,country_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "G9weroyz-0LX",
    "outputId": "189a004a-12f9-4514-9906-4c2c850c947d"
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# from selenium import webdriver\n",
    "# def main():\n",
    "#     a = webdriver.Chrome()\n",
    "#     a.get('https://www.google.com')\n",
    "#     time.sleep(5)\n",
    "#     a.quit()\n",
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "T3crarDT68ib",
    "outputId": "cc131011-6dde-4050-eefe-a387914beaa2"
   },
   "outputs": [],
   "source": [
    "# Creating a webdriver instance\n",
    "driver = webdriver.Chrome(\"ChromeDriver_Path/chromedriver\")\n",
    "# Opening the url we have just defined in our browser\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335000\n"
     ]
    }
   ],
   "source": [
    "#We find how many jobs are offered.\n",
    "jobs_num = driver.find_element(By.CSS_SELECTOR,\"h1>span\").get_attribute(\"innerText\")\n",
    "if len(jobs_num.split(',')) > 1:\n",
    "    jobs_num = int(jobs_num.split(',')[0])*1000\n",
    "else:\n",
    "    jobs_num = int(jobs_num)\n",
    "\n",
    "jobs_num   = int(jobs_num)\n",
    "print(jobs_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the numbers of jobs needed: 100\n"
     ]
    }
   ],
   "source": [
    "numbers = input(\"Enter the numbers of jobs needed: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current at:  52 Percentage at:  103.921568627451 % %\r"
     ]
    }
   ],
   "source": [
    "#We create a while loop to browse all jobs. \n",
    "numbers = int(numbers)\n",
    "i = 2\n",
    "while i <= int(numbers/2)+1:\n",
    "    #We keep scrollind down to the end of the view.\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    i = i + 1\n",
    "    print(\"Current at: \", i, \"Percentage at: \", ((i+1)/(int(numbers/2)+1))*100, \"%\",end=\"\\r\")\n",
    "    try:\n",
    "        #We try to click on the load more results buttons in case it is already displayed.\n",
    "        infinite_scroller_button = driver.find_element(By.XPATH, \".//button[@aria-label='Load more results']\")\n",
    "        infinite_scroller_button.click()\n",
    "        time.sleep(0.1)\n",
    "    except:\n",
    "        #If there is no button, there will be an error, so we keep scrolling down.\n",
    "        time.sleep(0.1)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist (Deep Learning), Peacock</td>\n",
       "      <td>Peacock</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Amicus</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jr. Data Scientist</td>\n",
       "      <td>UMortgage</td>\n",
       "      <td>Greater Philadelphia</td>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/jr-data-sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Pebble</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>2022-12-15</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Sunnyvale, CA</td>\n",
       "      <td>2022-12-15</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Pfizer</td>\n",
       "      <td>Peapack - Gladstone, NJ</td>\n",
       "      <td>2022-12-13</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>BioSpace</td>\n",
       "      <td>Pasadena, CA</td>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Insight Global</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>2022-12-07</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>FDA</td>\n",
       "      <td>Silver Spring, MD</td>\n",
       "      <td>2022-12-15</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Research Data Scientist</td>\n",
       "      <td>Nemours</td>\n",
       "      <td>Wilmington, DE</td>\n",
       "      <td>2022-12-07</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/research-da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Job Title         Company  \\\n",
       "0    Data Scientist (Deep Learning), Peacock         Peacock   \n",
       "1                             Data Scientist          Amicus   \n",
       "2                         Jr. Data Scientist       UMortgage   \n",
       "3                             Data Scientist          Pebble   \n",
       "4                             Data Scientist         Walmart   \n",
       "..                                       ...             ...   \n",
       "270                Machine Learning Engineer          Pfizer   \n",
       "271                Machine Learning Engineer        BioSpace   \n",
       "272                Machine Learning Engineer  Insight Global   \n",
       "273                           Data Scientist             FDA   \n",
       "274                  Research Data Scientist         Nemours   \n",
       "\n",
       "                    Location        Date  \\\n",
       "0               New York, NY  2022-12-06   \n",
       "1               New York, NY  2022-12-06   \n",
       "2       Greater Philadelphia  2022-12-09   \n",
       "3                Seattle, WA  2022-12-15   \n",
       "4              Sunnyvale, CA  2022-12-15   \n",
       "..                       ...         ...   \n",
       "270  Peapack - Gladstone, NJ  2022-12-13   \n",
       "271             Pasadena, CA  2022-12-12   \n",
       "272               Denver, CO  2022-12-07   \n",
       "273        Silver Spring, MD  2022-12-15   \n",
       "274           Wilmington, DE  2022-12-07   \n",
       "\n",
       "                                                  Link  \n",
       "0    https://www.linkedin.com/jobs/view/data-scient...  \n",
       "1    https://www.linkedin.com/jobs/view/data-scient...  \n",
       "2    https://www.linkedin.com/jobs/view/jr-data-sci...  \n",
       "3    https://www.linkedin.com/jobs/view/data-scient...  \n",
       "4    https://www.linkedin.com/jobs/view/data-scient...  \n",
       "..                                                 ...  \n",
       "270  https://www.linkedin.com/jobs/view/machine-lea...  \n",
       "271  https://www.linkedin.com/jobs/view/machine-lea...  \n",
       "272  https://www.linkedin.com/jobs/view/machine-lea...  \n",
       "273  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "274  https://www.linkedin.com/jobs/view/research-da...  \n",
       "\n",
       "[275 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We get a list containing all jobs that we have found.\n",
    "job_lists = driver.find_element(By.CLASS_NAME,\"jobs-search__results-list\")\n",
    "jobs = job_lists.find_elements(By.TAG_NAME,\"li\") # return a list\n",
    "\n",
    "#We declare void list to keep track of all obtaind data.\n",
    "job_title_list = []\n",
    "company_name_list = []\n",
    "location_list = []\n",
    "date_list = []\n",
    "job_link_list = []\n",
    "\n",
    "#We loof over every job and obtain all the wanted info.\n",
    "for job in jobs:\n",
    "    #job_title\n",
    "    job_title = job.find_element(By.CSS_SELECTOR,\"h3\").get_attribute(\"innerText\")\n",
    "    job_title_list.append(job_title)\n",
    "    \n",
    "    #company_name\n",
    "    company_name = job.find_element(By.CSS_SELECTOR,\"h4\").get_attribute(\"innerText\")\n",
    "    company_name_list.append(company_name)\n",
    "    \n",
    "    #location\n",
    "    location = job.find_element(By.CSS_SELECTOR,\"div>div>span\").get_attribute(\"innerText\")\n",
    "    location_list.append(location)\n",
    "    \n",
    "    #date\n",
    "    date = job.find_element(By.CSS_SELECTOR,\"div>div>time\").get_attribute(\"datetime\")\n",
    "    date_list.append(date)\n",
    "    \n",
    "    #job_link\n",
    "    job_link = job.find_element(By.CSS_SELECTOR,\"a\").get_attribute(\"href\")\n",
    "    job_link_list.append(job_link)\n",
    "\n",
    "jobs_df = pd.DataFrame({'Job Title': job_title_list,\n",
    "              'Company': company_name_list,\n",
    "              'Location': location_list,\n",
    "              'Date': date_list,\n",
    "              'Link': job_link_list\n",
    "            })\n",
    "jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "jobs_df.to_csv('Sample_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
